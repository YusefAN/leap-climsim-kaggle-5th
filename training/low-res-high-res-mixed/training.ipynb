{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28fa8305-e356-4a3a-b5dc-39c3ff04ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import AvgPool1d \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import LSTM, Conv1d, GRU, TransformerEncoder, TransformerEncoderLayer, BatchNorm1d, LayerNorm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torchmetrics.regression import R2Score\n",
    "import gc\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import hickle as hkl\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "from matplotlib.pyplot import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02065c49-f5b9-423a-bfe3-a0cf0cfe68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low-Res data and 1/15th of the high res data is preprocessed into .hkl files, each with 384*6 data points per files\n",
    "\n",
    "DATA_PATH = 'autodl-tmp/'\n",
    "\n",
    "file_list = glob(DATA_PATH+'CDFrag/'+'c_data_frag_x*hkl') #Path to low-res data\n",
    "file_list_mix = glob(DATA_PATH+'CDFrag L/'+'c_data_frag_x_*_1e-15.hkl') #Path to high-res data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1993d7a8-4b52-46c3-b612-d5f76bfa2c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34296"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8f6dcd-e762-4dc2-ad6a-d2938db5ddf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96672"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_list_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706c3681-81f4-4efe-a3d0-8c8b638827f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_fea_list = ['state_t','state_q0001','state_q0002','state_q0003','state_u','state_v','pbuf_ozone','pbuf_CH4','pbuf_N2O']\n",
    "num_fea_list = ['state_ps','pbuf_SOLIN','pbuf_LHFLX','pbuf_SHFLX','pbuf_TAUX','pbuf_TAUY','pbuf_COSZRS','cam_in_ALDIF','cam_in_ALDIR',\n",
    "                'cam_in_ASDIF','cam_in_ASDIR','cam_in_LWUP','cam_in_ICEFRAC','cam_in_LANDFRAC','cam_in_OCNFRAC','cam_in_SNOWHLAND']\n",
    "\n",
    "seq_y_list = ['ptend_t','ptend_q0001','ptend_q0002','ptend_q0003','ptend_u','ptend_v']\n",
    "num_y_list = ['cam_out_NETSW','cam_out_FLWDS','cam_out_PRECSC','cam_out_PRECC','cam_out_SOLS','cam_out_SOLL','cam_out_SOLSD','cam_out_SOLLD']\n",
    "\n",
    "seq_fea_expand_list = []\n",
    "for i in seq_fea_list:\n",
    "    for j in range(60):\n",
    "        seq_fea_expand_list.append(i+'_'+str(j))\n",
    "\n",
    "seq_y_expand_list = []\n",
    "for i in seq_y_list:\n",
    "    for j in range(60):\n",
    "        seq_y_expand_list.append(i+'_'+str(j))\n",
    "        \n",
    "norm_dict = dict()\n",
    "TARGET_COLS = seq_y_expand_list + num_y_list\n",
    "FEAT_COLS = seq_fea_expand_list + num_fea_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c3151eb-5315-4ce2-9257-e9ed6f912b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(FEAT_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d5452c-262b-4f4a-a1e2-db75bb0fed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a numpy dataset for loading the validation data\n",
    "class NumpyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        \"\"\"\n",
    "        Initialize with NumPy arrays.\n",
    "        \"\"\"\n",
    "        assert x.shape[0] == y.shape[0], \"Features and labels must have the same number of samples\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples.\n",
    "        \"\"\"\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generate one sample of data.\n",
    "        \"\"\"\n",
    "        # Convert the data to tensors when requested\n",
    "        return torch.from_numpy(self.x[index]).float().to(device), torch.from_numpy(self.y[index]).float().to(device)\n",
    "\n",
    "x_test = hkl.load(DATA_PATH+'x_test_v1_1e-15.hkl')\n",
    "x_valid = hkl.load(DATA_PATH+'c_data_x_8_1_v1_1e-15.hkl')\n",
    "y_valid = hkl.load(DATA_PATH+'c_data_y_8_1_v1_1e-15.hkl')\n",
    "\n",
    "val_dataset = NumpyDataset(x_valid, y_valid)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f02537b-2f9b-429e-ba2a-1177ea840b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define some helper functions\n",
    "def format_time(elapsed):\n",
    "    \"\"\"Take a time in seconds and return a string hh:mm:ss.\"\"\"\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28b00c-9e0c-4fce-a79f-4804148c71a6",
   "metadata": {},
   "source": [
    "# Definition of 3 Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde6032-954e-454f-8012-7f7af730a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroout_index = list(range(145,147)) #Indices to just have a 0 output\n",
    "zeroout_index = torch.tensor(list(set(zeroout_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0418e26-8f25-4c5b-b251-deb022372378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN_LSTM_888_AVG_ATT(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(FFNN_LSTM_888_AVG_ATT, self).__init__()\n",
    "        \n",
    "        self.encode_dim = 256\n",
    "        self.hidden_dim = 256\n",
    "        self.iter_dim = 800\n",
    "\n",
    "        self.LSTM_1 = LSTM(self.encode_dim,self.hidden_dim,6,batch_first=True,dropout=0.01,bidirectional=True)\n",
    "        self.input_size = input_size\n",
    "        self.Linear_1 = nn.Linear(len(seq_fea_list)+len(num_fea_list), self.encode_dim)\n",
    "        self.Linear_2 = nn.Linear(6*self.hidden_dim+self.encode_dim, self.iter_dim)\n",
    "        self.Linear_3 = nn.Linear(self.iter_dim, len(seq_y_list))\n",
    "        self.Linear_3_0 = nn.Linear(self.iter_dim, 1)\n",
    "\n",
    "        self.Linear_4_0 = nn.Linear(self.iter_dim, self.iter_dim*2)\n",
    "\n",
    "        self.Linear_4 = nn.Linear(self.iter_dim*2, len(num_y_list))\n",
    "        self.bias = nn.Linear(len(seq_y_list)*60+len(num_y_list),1)\n",
    "        self.weight = nn.Linear(len(seq_y_list)*60+len(num_y_list),1)\n",
    "        self.avg_pool_1 = AvgPool1d(kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_seq = x[:,0:60*len(seq_fea_list)]\n",
    "        x_seq = x_seq.reshape((-1,len(seq_fea_list),60))\n",
    "        x_seq = torch.transpose(x_seq, 1, 2)\n",
    "        \n",
    "        x_num = x[:,60*len(seq_fea_list):x.shape[1]]\n",
    "        x_num_repeat = x_num.reshape((-1,1,len(num_fea_list)))\n",
    "        x_num_repeat = x_num_repeat.repeat((1,60,1))\n",
    "        \n",
    "        x_seq = F.elu(self.Linear_1(torch.concat((x_seq,x_num_repeat),dim=-1)/5))\n",
    "        \n",
    "        x_seq_1,_ = self.LSTM_1(x_seq/5)\n",
    "        \n",
    "        x_seq_1_mean = torch.mean(x_seq_1,dim=1,keepdim=True)\n",
    "        x_seq_1_mean = x_seq_1_mean.repeat((1,60,1))\n",
    "\n",
    "        x_seq_1_avg_pool = self.avg_pool_1(torch.transpose(x_seq_1, 1, 2))\n",
    "        x_seq_1_avg_pool = torch.transpose(x_seq_1_avg_pool,1, 2)\n",
    "        \n",
    "        x_seq_1 = F.elu(self.Linear_2(torch.cat((x_seq_1,x_seq_1_mean,x_seq,x_seq_1_avg_pool),dim=-1)/5))\n",
    "        \n",
    "        att_weight = F.softmax(self.Linear_3_0(x_seq_1) - 10,dim=1)\n",
    "        \n",
    "        x_seq_out = self.Linear_3(x_seq_1)\n",
    "        x_seq_out = torch.transpose(x_seq_out, 1, 2)\n",
    "        x_seq_out = x_seq_out.reshape((-1,60*len(seq_y_list)))\n",
    "        \n",
    "        x_num_out = F.elu(self.Linear_4_0(torch.sum(att_weight*x_seq_1,dim=1)))\n",
    "        x_num_out = self.Linear_4(x_num_out)\n",
    "        \n",
    "        return self.weight.weight*(torch.concat((x_seq_out,x_num_out),dim=-1))/3+self.bias.weight/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee4b80-9fce-462f-9539-ed7e5dadb7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN_LSTM_6_AVG(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(FFNN_LSTM_6_AVG, self).__init__()\n",
    "        \n",
    "        self.encode_dim = 300\n",
    "        self.hidden_dim = 280\n",
    "        self.iter_dim = 800\n",
    "\n",
    "        self.LSTM_1 = LSTM(self.encode_dim,self.hidden_dim,6,batch_first=True,dropout=0.01,bidirectional=True)\n",
    "        self.input_size = input_size\n",
    "        self.Linear_1 = nn.Linear(len(seq_fea_list)+len(num_fea_list), self.encode_dim)\n",
    "        self.Linear_2 = nn.Linear(6*self.hidden_dim+self.encode_dim, self.iter_dim)\n",
    "        self.Linear_3 = nn.Linear(self.iter_dim, len(seq_y_list))\n",
    "        self.Linear_4_0 = nn.Linear(self.iter_dim, self.iter_dim*2)\n",
    "\n",
    "        self.Linear_4 = nn.Linear(self.iter_dim*2, len(num_y_list))\n",
    "        self.bias = nn.Linear(len(seq_y_list)*60+len(num_y_list),1)\n",
    "        self.weight = nn.Linear(len(seq_y_list)*60+len(num_y_list),1)\n",
    "        self.avg_pool_1 = AvgPool1d(kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_seq = x[:,0:60*len(seq_fea_list)]\n",
    "        x_seq = x_seq.reshape((-1,len(seq_fea_list),60))\n",
    "        x_seq = torch.transpose(x_seq, 1, 2)\n",
    "        \n",
    "        x_num = x[:,60*len(seq_fea_list):x.shape[1]]\n",
    "        x_num_repeat = x_num.reshape((-1,1,len(num_fea_list)))\n",
    "        x_num_repeat = x_num_repeat.repeat((1,60,1))\n",
    "        \n",
    "        x_seq = F.elu(self.Linear_1(torch.concat((x_seq,x_num_repeat),dim=-1)/5))\n",
    "        \n",
    "        x_seq_1,_ = self.LSTM_1(x_seq/5)\n",
    "        \n",
    "        x_seq_1_mean = torch.mean(x_seq_1,dim=1,keepdim=True)\n",
    "        x_seq_1_mean = x_seq_1_mean.repeat((1,60,1))\n",
    "\n",
    "        x_seq_1_avg_pool = self.avg_pool_1(torch.transpose(x_seq_1, 1, 2))\n",
    "        x_seq_1_avg_pool = torch.transpose(x_seq_1_avg_pool,1, 2)\n",
    "        \n",
    "        x_seq_1 = F.elu(self.Linear_2(torch.cat((x_seq_1,x_seq_1_mean,x_seq,x_seq_1_avg_pool),dim=-1)/5))\n",
    "        \n",
    "        x_seq_out = self.Linear_3(x_seq_1)\n",
    "        x_seq_out = torch.transpose(x_seq_out, 1, 2)\n",
    "        x_seq_out = x_seq_out.reshape((-1,60*len(seq_y_list)))\n",
    "        \n",
    "        x_num_out = F.elu(self.Linear_4_0(torch.mean(x_seq_1,dim=1)))\n",
    "        x_num_out = self.Linear_4(x_num_out)\n",
    "\n",
    "        output = self.weight.weight*(torch.concat((x_seq_out,x_num_out),dim=-1))/3+self.bias.weight/3\n",
    "        \n",
    "        output[:,zeroout_index] =  output[:,zeroout_index]*0.0\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5e820-1fcd-400a-9727-e5e4667ffa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN_LSTM_749_AVG_ATT(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(FFNN_LSTM_749_AVG_ATT, self).__init__()\n",
    "        \n",
    "        self.encode_dim = 256\n",
    "        self.hidden_dim = 320\n",
    "        self.iter_dim = 1024\n",
    "\n",
    "        self.LSTM_1 = LSTM(self.encode_dim,self.hidden_dim,6,batch_first=True,dropout=0.05,bidirectional=True)\n",
    "        self.input_size = input_size\n",
    "        self.Linear_1 = nn.Linear(len(seq_fea_list)+len(num_fea_list), self.encode_dim)\n",
    "        self.Linear_2 = nn.Linear(6*self.hidden_dim+self.encode_dim, self.iter_dim)\n",
    "        self.Linear_3 = nn.Linear(self.iter_dim, len(seq_y_list))\n",
    "        self.Linear_3_0 = nn.Linear(self.iter_dim, 1)\n",
    "\n",
    "        self.Linear_4_0 = nn.Linear(self.iter_dim, self.iter_dim*2)\n",
    "\n",
    "        self.Linear_4 = nn.Linear(self.iter_dim*2, len(num_y_list))\n",
    "        self.bias = nn.Linear(len(seq_y_list)*60+len(num_y_list),1)\n",
    "        self.weight = nn.Linear(len(seq_y_list)*60+len(num_y_list),1)\n",
    "        self.avg_pool_1 = AvgPool1d(kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_seq = x[:,0:60*len(seq_fea_list)]\n",
    "        x_seq = x_seq.reshape((-1,len(seq_fea_list),60))\n",
    "        x_seq = torch.transpose(x_seq, 1, 2)\n",
    "        \n",
    "        x_num = x[:,60*len(seq_fea_list):x.shape[1]]\n",
    "        x_num_repeat = x_num.reshape((-1,1,len(num_fea_list)))\n",
    "        x_num_repeat = x_num_repeat.repeat((1,60,1))\n",
    "        \n",
    "        x_seq = F.elu(self.Linear_1(torch.concat((x_seq,x_num_repeat),dim=-1)/5))\n",
    "        \n",
    "        x_seq_1,_ = self.LSTM_1(x_seq/5)\n",
    "        \n",
    "        x_seq_1_mean = torch.mean(x_seq_1,dim=1,keepdim=True)\n",
    "        x_seq_1_mean = x_seq_1_mean.repeat((1,60,1))\n",
    "\n",
    "        x_seq_1_avg_pool = self.avg_pool_1(torch.transpose(x_seq_1, 1, 2))\n",
    "        x_seq_1_avg_pool = torch.transpose(x_seq_1_avg_pool,1, 2)\n",
    "        \n",
    "        x_seq_1 = F.elu(self.Linear_2(torch.cat((x_seq_1,x_seq_1_mean,x_seq,x_seq_1_avg_pool),dim=-1)/5))\n",
    "        \n",
    "        att_weight = F.softmax(self.Linear_3_0(x_seq_1) - 10,dim=1)\n",
    "        \n",
    "        x_seq_out = self.Linear_3(x_seq_1)\n",
    "        x_seq_out = torch.transpose(x_seq_out, 1, 2)\n",
    "        x_seq_out = x_seq_out.reshape((-1,60*len(seq_y_list)))\n",
    "        \n",
    "        x_num_out = F.elu(self.Linear_4_0(torch.sum(att_weight*x_seq_1,dim=1)))\n",
    "        x_num_out = self.Linear_4(x_num_out)\n",
    "        \n",
    "        return self.weight.weight*(torch.concat((x_seq_out,x_num_out),dim=-1))/3+self.bias.weight/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77d2dd-bb46-4f5f-a507-21ca3c18826f",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35fb78-602e-44f9-959d-bb384c78deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 384*6*3\n",
    "MIN_STD = 1e-10\n",
    "SCHEDULER_PATIENCE = 6\n",
    "SCHEDULER_FACTOR = 10**(-0.2)\n",
    "EPOCHS = 70\n",
    "PATIENCE = 6\n",
    "PRINT_FREQ = 300\n",
    "BIN_NUM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "196cdadb-66a6-4e08-9e28-66968720518c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time after processing data: 0:00:00\n",
      "Time after all preparations: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Time after processing data:\", format_time(time.time()-ts), flush=True)    \n",
    "\n",
    "input_size = x_valid.shape[1]\n",
    "output_size = y_valid.shape[1]\n",
    "hidden_size = input_size + output_size\n",
    "\n",
    "model_single = FFNN_LSTM_6_AVG(input_size, output_size)\n",
    "device_ids = list(range(torch.cuda.device_count()))\n",
    "model = torch.nn.DataParallel(model_single)\n",
    "\n",
    "zeroout_index.to(device)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "criterion_l1 = nn.L1Loss()\n",
    "criterion_huber = nn.HuberLoss(delta=0.5)\n",
    "\n",
    "from ema_pytorch import EMA\n",
    "ema = EMA(\n",
    "    model,\n",
    "    beta = 0.99,              # exponential moving average factor\n",
    "    update_after_step = 50,    # only after this number of .update() calls will it start updating\n",
    "    update_every = 8,          # how often to actually update, to save on compute (updates every 10th .update() call)\n",
    ")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0002)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=SCHEDULER_FACTOR, patience=SCHEDULER_PATIENCE)\n",
    "\n",
    "print(\"Time after all preparations:\", format_time(time.time()-ts), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c22d3-9e84-47c2-b068-923ff56850b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Epoch: 2   Train Loss: 0.5134   LR: 1.0e-03   Time: 0:02:45\n",
      "  Epoch: 2   Train Loss: 0.5003   LR: 1.0e-03   Time: 0:05:16\n",
      "  Epoch: 2   Train Loss: 0.4746   LR: 1.0e-03   Time: 0:07:44\n",
      "  Epoch: 2   Train Loss: 0.4365   LR: 1.0e-03   Time: 0:10:15\n",
      "  Epoch: 2   Train Loss: 0.4026   LR: 1.0e-03   Time: 0:12:42\n",
      "  Epoch: 2   Train Loss: 0.3955   LR: 1.0e-03   Time: 0:15:12\n",
      "  Epoch: 2   Train Loss: 0.3608   LR: 1.0e-03   Time: 0:17:40\n",
      "  Epoch: 2   Train Loss: 0.3438   LR: 1.0e-03   Time: 0:20:11\n",
      "  Epoch: 2   Train Loss: 0.3138   LR: 1.0e-03   Time: 0:22:58\n",
      "  Epoch: 2   Train Loss: 0.3123   LR: 1.0e-03   Time: 0:25:42\n",
      "  Epoch: 2   Train Loss: 0.3019   LR: 1.0e-03   Time: 0:28:28\n",
      "  Epoch: 2   Train Loss: 0.3076   LR: 1.0e-03   Time: 0:31:16\n"
     ]
    }
   ],
   "source": [
    "time_gap = 0.00000005\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "patience_count = 0\n",
    "r2score = R2Score(num_outputs=y_valid.shape[1]).to(device)\n",
    "\n",
    "for epoch in range(1,400):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    random.shuffle(file_list)\n",
    "    random.shuffle(file_list_mix)\n",
    "    \n",
    "    if epoch > 9:\n",
    "        for g in optimizer.param_groups:\n",
    "            #g['lr'] = max(g['lr']*0.8,1e-4)\n",
    "            g['lr']  = 1e-4\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    model.train()\n",
    "    ema.train()\n",
    "    total_loss = 0\n",
    "    steps = 0\n",
    "    batch_idx = -1\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    batch_num = 105\n",
    "\n",
    "    x_train = np.zeros((batch_num*384*6,input_size),dtype=np.float32)\n",
    "    y_train = np.zeros((batch_num*384*6,output_size),dtype=np.float32)\n",
    "\n",
    "    x_train_mix = np.zeros((batch_num*384*6,input_size),dtype=np.float32)\n",
    "    y_train_mix = np.zeros((batch_num*384*6,output_size),dtype=np.float32)\n",
    "\n",
    "    for file_i in range(len(file_list)): \n",
    "        \n",
    "        y_tmp = hkl.load(file_list[file_i][0:30]+'y'+file_list[file_i][31:len(file_list[file_i])])\n",
    "        x_tmp = hkl.load(file_list[file_i])\n",
    "\n",
    "        y_tmp_mix = hkl.load(file_list_mix[file_i][0:32]+'y'+file_list_mix[file_i][33:len(file_list_mix[file_i])])\n",
    "        x_tmp_mix = hkl.load(file_list_mix[file_i])\n",
    "        \n",
    "        x_train[file_i%batch_num*384*6:file_i%batch_num*384*6+384*6,:] = x_tmp\n",
    "        y_train[file_i%batch_num*384*6:file_i%batch_num*384*6+384*6,:] = y_tmp\n",
    "\n",
    "        x_train_mix[file_i%batch_num*384*6:file_i%batch_num*384*6+384*6,:] = x_tmp_mix\n",
    "        y_train_mix[file_i%batch_num*384*6:file_i%batch_num*384*6+384*6,:] = y_tmp_mix\n",
    "\n",
    "        if (file_i+1)%batch_num == 0:\n",
    "            gc.collect()\n",
    "\n",
    "            y_train[:,zeroout_index] = y_train[:,zeroout_index]*0.0\n",
    "            y_train_mix[:,zeroout_index] = y_train_mix[:,zeroout_index]*0.0\n",
    "          \n",
    "            random_index = np.random.permutation(x_train.shape[0])\n",
    "            i1 = 0\n",
    "            for i in range(x_train.shape[0]//BATCH_SIZE+1):\n",
    "                time.sleep(time_gap)\n",
    "                i2 = np.minimum(i1 + BATCH_SIZE, x_train.shape[0])\n",
    "                if i1 == i2:  # Break the loop if range does not change\n",
    "                    break\n",
    "        \n",
    "                # Convert the current slice of xt to a PyTorch tensor\n",
    "                inputs = torch.from_numpy(x_train[random_index[i1:i2], :]).to(device)\n",
    "                batch_idx = batch_idx + 1\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                outputs_y = torch.from_numpy(y_train[random_index[i1:i2], :]).to(device)\n",
    "\n",
    "                inputs_mix = torch.from_numpy(x_train_mix[random_index[i1:i2], :]).to(device)\n",
    "\n",
    "                outputs_mix = model(inputs_mix)\n",
    "                outputs_y_mix = torch.from_numpy(y_train_mix[random_index[i1:i2], :]).to(device)\n",
    "\n",
    "                \n",
    "                loss = 0.08*criterion(outputs,outputs_y)+criterion_l1(outputs,outputs_y)\n",
    "                loss += 0.3*criterion_l1(outputs_mix,outputs_y_mix)\n",
    "                loss += 0.0005*criterion(outputs_mix,outputs_y_mix)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                ema.update()\n",
    "        \n",
    "                total_loss += loss.item()\n",
    "                steps += 1\n",
    "        \n",
    "                if (batch_idx + 1) % PRINT_FREQ == 0:\n",
    "                    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "                    elapsed_time = format_time(time.time() - ts)\n",
    "                    print(f'  Epoch: {epoch+1}',\\\n",
    "                          # f'  Batch: {batch_idx + 1}',\\\n",
    "                          f'  Train Loss: {total_loss / steps:.4f}',\\\n",
    "                          f'  LR: {current_lr:.1e}',\\\n",
    "                          f'  Time: {elapsed_time}', flush=True)\n",
    "                    with open('log0.txt', 'a') as file:\n",
    "                        file.write(f'  Epoch: {epoch+1}  Train Loss: {total_loss / steps:.4f}  LR: {current_lr:.1e} Time: {elapsed_time}' + '\\n')\n",
    "                    total_loss = 0\n",
    "                    steps = 0\n",
    "        \n",
    "                # No need to track gradients for inference\n",
    "                i1 = i2  # Update i1 to the end of the current batch\n",
    "                if i2 >= x_train.shape[0]:\n",
    "                    break\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    y_true = torch.tensor([], device=device)\n",
    "    all_outputs = torch.tensor([], device=device)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader):\n",
    "            time.sleep(time_gap)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            y_true = torch.cat((y_true, labels), 0)\n",
    "            all_outputs = torch.cat((all_outputs, outputs), 0)\n",
    "    \n",
    "    r2=0\n",
    "    r2_broken = []\n",
    "    r2_broken_names = []\n",
    "    for i in range(368):\n",
    "        r2_i = r2score(all_outputs[:, i], y_true[:, i])\n",
    "        if r2_i > 1e-6:\n",
    "            r2 += r2_i\n",
    "        else:\n",
    "            r2_broken.append(i)\n",
    "            r2_broken_names.append(FEAT_COLS[i])\n",
    "    r2 /= 368\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f'\\nEpoch: {epoch+1}  Val Loss: {avg_val_loss:.4f}  R2 score: {r2:.4f}')\n",
    "    print(f'{len(r2_broken)} targets were excluded during evaluation of R2 score.')\n",
    "    with open('log0.txt', 'a') as file:\n",
    "            file.write(f'\\nEpoch: {epoch+1}  Val Loss: {avg_val_loss:.4f}  R2 score: {r2:.4f}' + '\\n')\n",
    "\n",
    "    scheduler.step(round(avg_val_loss*2,4))\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        patience_count = 0\n",
    "        print(\"Validation loss decreased, saving new best model and resetting patience counter.\")\n",
    "    else:\n",
    "        patience_count += 1\n",
    "        print(f\"No improvement in validation loss for {patience_count} epochs.\")\n",
    "        \n",
    "    if patience_count >= PATIENCE:\n",
    "        print(\"Stopping early due to no improvement in validation loss.\")\n",
    "        break\n",
    "    \n",
    "    ema.eval()\n",
    "    val_loss = 0\n",
    "    y_true = torch.tensor([], device=device)\n",
    "    all_outputs = torch.tensor([], device=device)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader):\n",
    "            time.sleep(time_gap)\n",
    "\n",
    "            outputs = ema(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            y_true = torch.cat((y_true, labels), 0)\n",
    "            all_outputs = torch.cat((all_outputs, outputs), 0)\n",
    "    valid_results = all_outputs.to('cpu').numpy()\n",
    "\n",
    "    r2=0\n",
    "    r2_broken = []\n",
    "    r2_broken_names = []\n",
    "    for i in range(368):\n",
    "        r2_i = r2score(all_outputs[:, i], y_true[:, i])\n",
    "        if r2_i > 1e-6:\n",
    "            r2 += r2_i\n",
    "        else:\n",
    "            r2_broken.append(i)\n",
    "            r2_broken_names.append(FEAT_COLS[i])\n",
    "    r2 /= 368\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f'\\nEpoch: {epoch+1}  Val Loss: {avg_val_loss:.4f}  R2 score: {r2:.4f}')\n",
    "    with open('log0.txt', 'a') as file:\n",
    "        file.write(f'\\nEpoch: {epoch+1}  Val Loss: {avg_val_loss:.4f}  R2 score: {r2:.4f}' + '\\n')\n",
    "    print(f'{len(r2_broken)} targets were excluded during evaluation of R2 score.')\n",
    "\n",
    "    predt = np.zeros([x_test.shape[0], output_size], dtype=np.float32)\n",
    "\n",
    "    if epoch%1==0 and epoch>0:\n",
    "        i1 = 0\n",
    "        for i in tqdm(range(10000)):\n",
    "            time.sleep(time_gap)\n",
    "\n",
    "            i2 = np.minimum(i1 + BATCH_SIZE, x_test.shape[0])\n",
    "            if i1 == i2:  # Break the loop if range does not change\n",
    "                break\n",
    "    \n",
    "            # Convert the current slice of xt to a PyTorch tensor\n",
    "            inputs = torch.from_numpy(x_test[i1:i2, :]).float().to(device)\n",
    "    \n",
    "            # No need to track gradients for inference\n",
    "            with torch.no_grad():\n",
    "                outputs = ema(inputs)  # Get model predictions\n",
    "                predt[i1:i2, :] = outputs.cpu().numpy()  # Store predictions in predt\n",
    "    \n",
    "            i1 = i2  # Update i1 to the end of the current batch\n",
    "    \n",
    "            if i2 >= x_test.shape[0]:\n",
    "                break\n",
    "                \n",
    "        hkl.dump(predt, DATA_PATH+'FFNN_LSTM_999_AVG_ATT_'+str(epoch)+'_mix_1e-15.hkl', compression='gzip')\n",
    "        torch.save(model.state_dict(), DATA_PATH+'FFNN_LSTM_999_AVG_ATT_1e-15_'+str(epoch)+'.pt')\n",
    "        torch.save(ema.state_dict(), DATA_PATH+'FFNN_LSTM_999_AVG_ATT_1e-15_ema_'+str(epoch)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18868e-c0a1-4f60-a0a8-e174a093f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ema.state_dict(), DATA_PATH+'FFNN_LSTM_6_AVG_1e-15_ema_'+str(epoch)+'.pt')\n",
    "torch.save(model.state_dict(), DATA_PATH+'FFNN_LSTM_6_AVG_1e-15_'+str(epoch)+'.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
